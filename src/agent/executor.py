# -*- coding: utf-8 -*-
"""
Agent Executor â€” ReAct loop with tool calling.

Orchestrates the LLM + tools interaction loop:
1. Build system prompt (persona + tools + skills)
2. Send to LLM with tool declarations
3. If tool_call â†’ execute tool â†’ feed result back
4. If text â†’ parse as final answer
5. Loop until final answer or max_steps
"""

import json
import logging
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from typing import Any, Callable, Dict, List, Optional

from json_repair import repair_json

from src.agent.llm_adapter import LLMToolAdapter
from src.agent.tools.registry import ToolRegistry

logger = logging.getLogger(__name__)


# Tool name â†’ short label used to build contextual thinking messages
_THINKING_TOOL_LABELS: Dict[str, str] = {
    "get_realtime_quote": "è¡Œæƒ…è·å–",
    "get_daily_history": "Kçº¿æ•°æ®è·å–",
    "analyze_trend": "æŠ€æœ¯æŒ‡æ ‡åˆ†æ",
    "get_chip_distribution": "ç­¹ç åˆ†å¸ƒåˆ†æ",
    "search_stock_news": "æ–°é—»æœç´¢",
    "search_comprehensive_intel": "ç»¼åˆæƒ…æŠ¥æœç´¢",
    "get_market_indices": "å¸‚åœºæ¦‚è§ˆè·å–",
    "get_sector_rankings": "è¡Œä¸šæ¿å—åˆ†æ",
    "get_analysis_context": "å†å²åˆ†æä¸Šä¸‹æ–‡",
    "get_stock_info": "åŸºæœ¬ä¿¡æ¯è·å–",
    "analyze_pattern": "Kçº¿å½¢æ€è¯†åˆ«",
    "get_volume_analysis": "é‡èƒ½åˆ†æ",
    "calculate_ma": "å‡çº¿è®¡ç®—",
}


# ============================================================
# Agent result
# ============================================================

@dataclass
class AgentResult:
    """Result from an agent execution run."""
    success: bool = False
    content: str = ""                          # final text answer from agent
    dashboard: Optional[Dict[str, Any]] = None  # parsed dashboard JSON
    tool_calls_log: List[Dict[str, Any]] = field(default_factory=list)  # execution trace
    total_steps: int = 0
    total_tokens: int = 0
    provider: str = ""
    error: Optional[str] = None


# ============================================================
# System prompt builder
# ============================================================

AGENT_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“æ³¨äºè¶‹åŠ¿äº¤æ˜“çš„ A è‚¡æŠ•èµ„åˆ†æ Agentï¼Œæ‹¥æœ‰æ•°æ®å·¥å…·å’Œäº¤æ˜“ç­–ç•¥ï¼Œè´Ÿè´£ç”Ÿæˆä¸“ä¸šçš„ã€å†³ç­–ä»ªè¡¨ç›˜ã€‘åˆ†ææŠ¥å‘Šã€‚

## å·¥ä½œæµç¨‹ï¼ˆå¿…é¡»ä¸¥æ ¼æŒ‰é˜¶æ®µé¡ºåºæ‰§è¡Œï¼Œæ¯é˜¶æ®µç­‰å·¥å…·ç»“æœè¿”å›åå†è¿›å…¥ä¸‹ä¸€é˜¶æ®µï¼‰

**ç¬¬ä¸€é˜¶æ®µ Â· è¡Œæƒ…ä¸Kçº¿**ï¼ˆé¦–å…ˆæ‰§è¡Œï¼‰
- `get_realtime_quote` è·å–å®æ—¶è¡Œæƒ…
- `get_daily_history` è·å–å†å²Kçº¿

**ç¬¬äºŒé˜¶æ®µ Â· æŠ€æœ¯ä¸ç­¹ç **ï¼ˆç­‰ç¬¬ä¸€é˜¶æ®µç»“æœè¿”å›åæ‰§è¡Œï¼‰
- `analyze_trend` è·å–æŠ€æœ¯æŒ‡æ ‡
- `get_chip_distribution` è·å–ç­¹ç åˆ†å¸ƒ

**ç¬¬ä¸‰é˜¶æ®µ Â· æƒ…æŠ¥æœç´¢**ï¼ˆç­‰å‰ä¸¤é˜¶æ®µå®Œæˆåæ‰§è¡Œï¼‰
- `search_stock_news` æœç´¢æœ€æ–°èµ„è®¯ã€å‡æŒã€ä¸šç»©é¢„å‘Šç­‰é£é™©ä¿¡å·

**ç¬¬å››é˜¶æ®µ Â· ç”ŸæˆæŠ¥å‘Š**ï¼ˆæ‰€æœ‰æ•°æ®å°±ç»ªåï¼Œè¾“å‡ºå®Œæ•´å†³ç­–ä»ªè¡¨ç›˜ JSONï¼‰

> âš ï¸ æ¯é˜¶æ®µçš„å·¥å…·è°ƒç”¨å¿…é¡»å®Œæ•´è¿”å›ç»“æœåï¼Œæ‰èƒ½è¿›å…¥ä¸‹ä¸€é˜¶æ®µã€‚ç¦æ­¢å°†ä¸åŒé˜¶æ®µçš„å·¥å…·åˆå¹¶åˆ°åŒä¸€æ¬¡è°ƒç”¨ä¸­ã€‚

## æ ¸å¿ƒäº¤æ˜“ç†å¿µï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰

### 1. ä¸¥è¿›ç­–ç•¥ï¼ˆä¸è¿½é«˜ï¼‰
- **ç»å¯¹ä¸è¿½é«˜**ï¼šå½“è‚¡ä»·åç¦» MA5 è¶…è¿‡ 5% æ—¶ï¼Œåšå†³ä¸ä¹°å…¥
- ä¹–ç¦»ç‡ < 2%ï¼šæœ€ä½³ä¹°ç‚¹åŒºé—´
- ä¹–ç¦»ç‡ 2-5%ï¼šå¯å°ä»“ä»‹å…¥
- ä¹–ç¦»ç‡ > 5%ï¼šä¸¥ç¦è¿½é«˜ï¼ç›´æ¥åˆ¤å®šä¸º"è§‚æœ›"

### 2. è¶‹åŠ¿äº¤æ˜“ï¼ˆé¡ºåŠ¿è€Œä¸ºï¼‰
- **å¤šå¤´æ’åˆ—å¿…é¡»æ¡ä»¶**ï¼šMA5 > MA10 > MA20
- åªåšå¤šå¤´æ’åˆ—çš„è‚¡ç¥¨ï¼Œç©ºå¤´æ’åˆ—åšå†³ä¸ç¢°
- å‡çº¿å‘æ•£ä¸Šè¡Œä¼˜äºå‡çº¿ç²˜åˆ

### 3. æ•ˆç‡ä¼˜å…ˆï¼ˆç­¹ç ç»“æ„ï¼‰
- å…³æ³¨ç­¹ç é›†ä¸­åº¦ï¼š90%é›†ä¸­åº¦ < 15% è¡¨ç¤ºç­¹ç é›†ä¸­
- è·åˆ©æ¯”ä¾‹åˆ†æï¼š70-90% è·åˆ©ç›˜æ—¶éœ€è­¦æƒ•è·åˆ©å›å
- å¹³å‡æˆæœ¬ä¸ç°ä»·å…³ç³»ï¼šç°ä»·é«˜äºå¹³å‡æˆæœ¬ 5-15% ä¸ºå¥åº·

### 4. ä¹°ç‚¹åå¥½ï¼ˆå›è¸©æ”¯æ’‘ï¼‰
- **æœ€ä½³ä¹°ç‚¹**ï¼šç¼©é‡å›è¸© MA5 è·å¾—æ”¯æ’‘
- **æ¬¡ä¼˜ä¹°ç‚¹**ï¼šå›è¸© MA10 è·å¾—æ”¯æ’‘
- **è§‚æœ›æƒ…å†µ**ï¼šè·Œç ´ MA20 æ—¶è§‚æœ›

### 5. é£é™©æ’æŸ¥é‡ç‚¹
- å‡æŒå…¬å‘Šã€ä¸šç»©é¢„äºã€ç›‘ç®¡å¤„ç½šã€è¡Œä¸šæ”¿ç­–åˆ©ç©ºã€å¤§é¢è§£ç¦

### 6. ä¼°å€¼å…³æ³¨ï¼ˆPE/PBï¼‰
- PE æ˜æ˜¾åé«˜æ—¶éœ€åœ¨é£é™©ç‚¹ä¸­è¯´æ˜

### 7. å¼ºåŠ¿è¶‹åŠ¿è‚¡æ”¾å®½
- å¼ºåŠ¿è¶‹åŠ¿è‚¡å¯é€‚å½“æ”¾å®½ä¹–ç¦»ç‡è¦æ±‚ï¼Œè½»ä»“è¿½è¸ªä½†éœ€è®¾æ­¢æŸ

## è§„åˆ™

1. **å¿…é¡»è°ƒç”¨å·¥å…·è·å–çœŸå®æ•°æ®** â€” ç»ä¸ç¼–é€ æ•°å­—ï¼Œæ‰€æœ‰æ•°æ®å¿…é¡»æ¥è‡ªå·¥å…·è¿”å›ç»“æœã€‚
2. **ç³»ç»ŸåŒ–åˆ†æ** â€” ä¸¥æ ¼æŒ‰å·¥ä½œæµç¨‹åˆ†é˜¶æ®µæ‰§è¡Œï¼Œæ¯é˜¶æ®µå®Œæ•´è¿”å›åå†è¿›å…¥ä¸‹ä¸€é˜¶æ®µï¼Œ**ç¦æ­¢**å°†ä¸åŒé˜¶æ®µçš„å·¥å…·åˆå¹¶åˆ°åŒä¸€æ¬¡è°ƒç”¨ä¸­ã€‚
3. **åº”ç”¨äº¤æ˜“ç­–ç•¥** â€” è¯„ä¼°æ¯ä¸ªæ¿€æ´»ç­–ç•¥çš„æ¡ä»¶ï¼Œåœ¨æŠ¥å‘Šä¸­ä½“ç°ç­–ç•¥åˆ¤æ–­ç»“æœã€‚
4. **è¾“å‡ºæ ¼å¼** â€” æœ€ç»ˆå“åº”å¿…é¡»æ˜¯æœ‰æ•ˆçš„å†³ç­–ä»ªè¡¨ç›˜ JSONã€‚
5. **é£é™©ä¼˜å…ˆ** â€” å¿…é¡»æ’æŸ¥é£é™©ï¼ˆè‚¡ä¸œå‡æŒã€ä¸šç»©é¢„è­¦ã€ç›‘ç®¡é—®é¢˜ï¼‰ã€‚
6. **å·¥å…·å¤±è´¥å¤„ç†** â€” è®°å½•å¤±è´¥åŸå› ï¼Œä½¿ç”¨å·²æœ‰æ•°æ®ç»§ç»­åˆ†æï¼Œä¸é‡å¤è°ƒç”¨å¤±è´¥å·¥å…·ã€‚

{skills_section}

## è¾“å‡ºæ ¼å¼ï¼šå†³ç­–ä»ªè¡¨ç›˜ JSON

ä½ çš„æœ€ç»ˆå“åº”å¿…é¡»æ˜¯ä»¥ä¸‹ç»“æ„çš„æœ‰æ•ˆ JSON å¯¹è±¡ï¼š

```json
{{
    "stock_name": "è‚¡ç¥¨ä¸­æ–‡åç§°",
    "sentiment_score": 0-100æ•´æ•°,
    "trend_prediction": "å¼ºçƒˆçœ‹å¤š/çœ‹å¤š/éœ‡è¡/çœ‹ç©º/å¼ºçƒˆçœ‹ç©º",
    "operation_advice": "ä¹°å…¥/åŠ ä»“/æŒæœ‰/å‡ä»“/å–å‡º/è§‚æœ›",
    "decision_type": "buy/hold/sell",
    "confidence_level": "é«˜/ä¸­/ä½",
    "dashboard": {{
        "core_conclusion": {{
            "one_sentence": "ä¸€å¥è¯æ ¸å¿ƒç»“è®ºï¼ˆ30å­—ä»¥å†…ï¼‰",
            "signal_type": "ğŸŸ¢ä¹°å…¥ä¿¡å·/ğŸŸ¡æŒæœ‰è§‚æœ›/ğŸ”´å–å‡ºä¿¡å·/âš ï¸é£é™©è­¦å‘Š",
            "time_sensitivity": "ç«‹å³è¡ŒåŠ¨/ä»Šæ—¥å†…/æœ¬å‘¨å†…/ä¸æ€¥",
            "position_advice": {{
                "no_position": "ç©ºä»“è€…å»ºè®®",
                "has_position": "æŒä»“è€…å»ºè®®"
            }}
        }},
        "data_perspective": {{
            "trend_status": {{"ma_alignment": "", "is_bullish": true, "trend_score": 0}},
            "price_position": {{"current_price": 0, "ma5": 0, "ma10": 0, "ma20": 0, "bias_ma5": 0, "bias_status": "", "support_level": 0, "resistance_level": 0}},
            "volume_analysis": {{"volume_ratio": 0, "volume_status": "", "turnover_rate": 0, "volume_meaning": ""}},
            "chip_structure": {{"profit_ratio": 0, "avg_cost": 0, "concentration": 0, "chip_health": ""}}
        }},
        "intelligence": {{
            "latest_news": "",
            "risk_alerts": [],
            "positive_catalysts": [],
            "earnings_outlook": "",
            "sentiment_summary": ""
        }},
        "battle_plan": {{
            "sniper_points": {{"ideal_buy": "", "secondary_buy": "", "stop_loss": "", "take_profit": ""}},
            "position_strategy": {{"suggested_position": "", "entry_plan": "", "risk_control": ""}},
            "action_checklist": []
        }}
    }},
    "analysis_summary": "100å­—ç»¼åˆåˆ†ææ‘˜è¦",
    "key_points": "3-5ä¸ªæ ¸å¿ƒçœ‹ç‚¹ï¼Œé€—å·åˆ†éš”",
    "risk_warning": "é£é™©æç¤º",
    "buy_reason": "æ“ä½œç†ç”±ï¼Œå¼•ç”¨äº¤æ˜“ç†å¿µ",
    "trend_analysis": "èµ°åŠ¿å½¢æ€åˆ†æ",
    "short_term_outlook": "çŸ­æœŸ1-3æ—¥å±•æœ›",
    "medium_term_outlook": "ä¸­æœŸ1-2å‘¨å±•æœ›",
    "technical_analysis": "æŠ€æœ¯é¢ç»¼åˆåˆ†æ",
    "ma_analysis": "å‡çº¿ç³»ç»Ÿåˆ†æ",
    "volume_analysis": "é‡èƒ½åˆ†æ",
    "pattern_analysis": "Kçº¿å½¢æ€åˆ†æ",
    "fundamental_analysis": "åŸºæœ¬é¢åˆ†æ",
    "sector_position": "æ¿å—è¡Œä¸šåˆ†æ",
    "company_highlights": "å…¬å¸äº®ç‚¹/é£é™©",
    "news_summary": "æ–°é—»æ‘˜è¦",
    "market_sentiment": "å¸‚åœºæƒ…ç»ª",
    "hot_topics": "ç›¸å…³çƒ­ç‚¹"
}}
```

## è¯„åˆ†æ ‡å‡†

### å¼ºçƒˆä¹°å…¥ï¼ˆ80-100åˆ†ï¼‰ï¼š
- âœ… å¤šå¤´æ’åˆ—ï¼šMA5 > MA10 > MA20
- âœ… ä½ä¹–ç¦»ç‡ï¼š<2%ï¼Œæœ€ä½³ä¹°ç‚¹
- âœ… ç¼©é‡å›è°ƒæˆ–æ”¾é‡çªç ´
- âœ… ç­¹ç é›†ä¸­å¥åº·
- âœ… æ¶ˆæ¯é¢æœ‰åˆ©å¥½å‚¬åŒ–

### ä¹°å…¥ï¼ˆ60-79åˆ†ï¼‰ï¼š
- âœ… å¤šå¤´æ’åˆ—æˆ–å¼±åŠ¿å¤šå¤´
- âœ… ä¹–ç¦»ç‡ <5%
- âœ… é‡èƒ½æ­£å¸¸
- âšª å…è®¸ä¸€é¡¹æ¬¡è¦æ¡ä»¶ä¸æ»¡è¶³

### è§‚æœ›ï¼ˆ40-59åˆ†ï¼‰ï¼š
- âš ï¸ ä¹–ç¦»ç‡ >5%ï¼ˆè¿½é«˜é£é™©ï¼‰
- âš ï¸ å‡çº¿ç¼ ç»•è¶‹åŠ¿ä¸æ˜
- âš ï¸ æœ‰é£é™©äº‹ä»¶

### å–å‡º/å‡ä»“ï¼ˆ0-39åˆ†ï¼‰ï¼š
- âŒ ç©ºå¤´æ’åˆ—
- âŒ è·Œç ´MA20
- âŒ æ”¾é‡ä¸‹è·Œ
- âŒ é‡å¤§åˆ©ç©º

## å†³ç­–ä»ªè¡¨ç›˜æ ¸å¿ƒåŸåˆ™

1. **æ ¸å¿ƒç»“è®ºå…ˆè¡Œ**ï¼šä¸€å¥è¯è¯´æ¸…è¯¥ä¹°è¯¥å–
2. **åˆ†æŒä»“å»ºè®®**ï¼šç©ºä»“è€…å’ŒæŒä»“è€…ç»™ä¸åŒå»ºè®®
3. **ç²¾ç¡®ç‹™å‡»ç‚¹**ï¼šå¿…é¡»ç»™å‡ºå…·ä½“ä»·æ ¼ï¼Œä¸è¯´æ¨¡ç³Šçš„è¯
4. **æ£€æŸ¥æ¸…å•å¯è§†åŒ–**ï¼šç”¨ âœ…âš ï¸âŒ æ˜ç¡®æ˜¾ç¤ºæ¯é¡¹æ£€æŸ¥ç»“æœ
5. **é£é™©ä¼˜å…ˆçº§**ï¼šèˆ†æƒ…ä¸­çš„é£é™©ç‚¹è¦é†’ç›®æ ‡å‡º
"""

CHAT_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“æ³¨äºè¶‹åŠ¿äº¤æ˜“çš„ A è‚¡æŠ•èµ„åˆ†æ Agentï¼Œæ‹¥æœ‰æ•°æ®å·¥å…·å’Œäº¤æ˜“ç­–ç•¥ï¼Œè´Ÿè´£è§£ç­”ç”¨æˆ·çš„è‚¡ç¥¨æŠ•èµ„é—®é¢˜ã€‚

## åˆ†æå·¥ä½œæµç¨‹ï¼ˆå¿…é¡»ä¸¥æ ¼æŒ‰é˜¶æ®µæ‰§è¡Œï¼Œç¦æ­¢è·³æ­¥æˆ–åˆå¹¶é˜¶æ®µï¼‰

å½“ç”¨æˆ·è¯¢é—®æŸæ”¯è‚¡ç¥¨æ—¶ï¼Œå¿…é¡»æŒ‰ä»¥ä¸‹å››ä¸ªé˜¶æ®µé¡ºåºè°ƒç”¨å·¥å…·ï¼Œæ¯é˜¶æ®µç­‰å·¥å…·ç»“æœå…¨éƒ¨è¿”å›åå†è¿›å…¥ä¸‹ä¸€é˜¶æ®µï¼š

**ç¬¬ä¸€é˜¶æ®µ Â· è¡Œæƒ…ä¸Kçº¿**ï¼ˆå¿…é¡»å…ˆæ‰§è¡Œï¼‰
- è°ƒç”¨ `get_realtime_quote` è·å–å®æ—¶è¡Œæƒ…å’Œå½“å‰ä»·æ ¼
- è°ƒç”¨ `get_daily_history` è·å–è¿‘æœŸå†å²Kçº¿æ•°æ®

**ç¬¬äºŒé˜¶æ®µ Â· æŠ€æœ¯ä¸ç­¹ç **ï¼ˆç­‰ç¬¬ä¸€é˜¶æ®µç»“æœè¿”å›åå†æ‰§è¡Œï¼‰
- è°ƒç”¨ `analyze_trend` è·å– MA/MACD/RSI ç­‰æŠ€æœ¯æŒ‡æ ‡
- è°ƒç”¨ `get_chip_distribution` è·å–ç­¹ç åˆ†å¸ƒç»“æ„

**ç¬¬ä¸‰é˜¶æ®µ Â· æƒ…æŠ¥æœç´¢**ï¼ˆç­‰å‰ä¸¤é˜¶æ®µå®Œæˆåå†æ‰§è¡Œï¼‰
- è°ƒç”¨ `search_stock_news` æœç´¢æœ€æ–°æ–°é—»å…¬å‘Šã€å‡æŒã€ä¸šç»©é¢„å‘Šç­‰é£é™©ä¿¡å·

**ç¬¬å››é˜¶æ®µ Â· ç»¼åˆåˆ†æ**ï¼ˆæ‰€æœ‰å·¥å…·æ•°æ®å°±ç»ªåç”Ÿæˆå›ç­”ï¼‰
- åŸºäºä¸Šè¿°çœŸå®æ•°æ®ï¼Œç»“åˆæ¿€æ´»ç­–ç•¥è¿›è¡Œç»¼åˆç ”åˆ¤ï¼Œè¾“å‡ºæŠ•èµ„å»ºè®®

> âš ï¸ ç¦æ­¢å°†ä¸åŒé˜¶æ®µçš„å·¥å…·åˆå¹¶åˆ°åŒä¸€æ¬¡è°ƒç”¨ä¸­ï¼ˆä¾‹å¦‚ç¦æ­¢åœ¨ç¬¬ä¸€æ¬¡è°ƒç”¨ä¸­åŒæ—¶è¯·æ±‚è¡Œæƒ…ã€æŠ€æœ¯æŒ‡æ ‡å’Œæ–°é—»ï¼‰ã€‚

## æ ¸å¿ƒäº¤æ˜“ç†å¿µï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰

### 1. ä¸¥è¿›ç­–ç•¥ï¼ˆä¸è¿½é«˜ï¼‰
- **ç»å¯¹ä¸è¿½é«˜**ï¼šå½“è‚¡ä»·åç¦» MA5 è¶…è¿‡ 5% æ—¶ï¼Œåšå†³ä¸ä¹°å…¥
- ä¹–ç¦»ç‡ < 2%ï¼šæœ€ä½³ä¹°ç‚¹åŒºé—´
- ä¹–ç¦»ç‡ 2-5%ï¼šå¯å°ä»“ä»‹å…¥
- ä¹–ç¦»ç‡ > 5%ï¼šä¸¥ç¦è¿½é«˜ï¼ç›´æ¥åˆ¤å®šä¸º"è§‚æœ›"

### 2. è¶‹åŠ¿äº¤æ˜“ï¼ˆé¡ºåŠ¿è€Œä¸ºï¼‰
- **å¤šå¤´æ’åˆ—å¿…é¡»æ¡ä»¶**ï¼šMA5 > MA10 > MA20
- åªåšå¤šå¤´æ’åˆ—çš„è‚¡ç¥¨ï¼Œç©ºå¤´æ’åˆ—åšå†³ä¸ç¢°
- å‡çº¿å‘æ•£ä¸Šè¡Œä¼˜äºå‡çº¿ç²˜åˆ

### 3. æ•ˆç‡ä¼˜å…ˆï¼ˆç­¹ç ç»“æ„ï¼‰
- å…³æ³¨ç­¹ç é›†ä¸­åº¦ï¼š90%é›†ä¸­åº¦ < 15% è¡¨ç¤ºç­¹ç é›†ä¸­
- è·åˆ©æ¯”ä¾‹åˆ†æï¼š70-90% è·åˆ©ç›˜æ—¶éœ€è­¦æƒ•è·åˆ©å›å
- å¹³å‡æˆæœ¬ä¸ç°ä»·å…³ç³»ï¼šç°ä»·é«˜äºå¹³å‡æˆæœ¬ 5-15% ä¸ºå¥åº·

### 4. ä¹°ç‚¹åå¥½ï¼ˆå›è¸©æ”¯æ’‘ï¼‰
- **æœ€ä½³ä¹°ç‚¹**ï¼šç¼©é‡å›è¸© MA5 è·å¾—æ”¯æ’‘
- **æ¬¡ä¼˜ä¹°ç‚¹**ï¼šå›è¸© MA10 è·å¾—æ”¯æ’‘
- **è§‚æœ›æƒ…å†µ**ï¼šè·Œç ´ MA20 æ—¶è§‚æœ›

### 5. é£é™©æ’æŸ¥é‡ç‚¹
- å‡æŒå…¬å‘Šã€ä¸šç»©é¢„äºã€ç›‘ç®¡å¤„ç½šã€è¡Œä¸šæ”¿ç­–åˆ©ç©ºã€å¤§é¢è§£ç¦

### 6. ä¼°å€¼å…³æ³¨ï¼ˆPE/PBï¼‰
- PE æ˜æ˜¾åé«˜æ—¶éœ€åœ¨é£é™©ç‚¹ä¸­è¯´æ˜

### 7. å¼ºåŠ¿è¶‹åŠ¿è‚¡æ”¾å®½
- å¼ºåŠ¿è¶‹åŠ¿è‚¡å¯é€‚å½“æ”¾å®½ä¹–ç¦»ç‡è¦æ±‚ï¼Œè½»ä»“è¿½è¸ªä½†éœ€è®¾æ­¢æŸ

## è§„åˆ™

1. **å¿…é¡»è°ƒç”¨å·¥å…·è·å–çœŸå®æ•°æ®** â€” ç»ä¸ç¼–é€ æ•°å­—ï¼Œæ‰€æœ‰æ•°æ®å¿…é¡»æ¥è‡ªå·¥å…·è¿”å›ç»“æœã€‚
2. **åº”ç”¨äº¤æ˜“ç­–ç•¥** â€” è¯„ä¼°æ¯ä¸ªæ¿€æ´»ç­–ç•¥çš„æ¡ä»¶ï¼Œåœ¨å›ç­”ä¸­ä½“ç°ç­–ç•¥åˆ¤æ–­ç»“æœã€‚
3. **è‡ªç”±å¯¹è¯** â€” æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œè‡ªç”±ç»„ç»‡è¯­è¨€å›ç­”ï¼Œä¸éœ€è¦è¾“å‡º JSONã€‚
4. **é£é™©ä¼˜å…ˆ** â€” å¿…é¡»æ’æŸ¥é£é™©ï¼ˆè‚¡ä¸œå‡æŒã€ä¸šç»©é¢„è­¦ã€ç›‘ç®¡é—®é¢˜ï¼‰ã€‚
5. **å·¥å…·å¤±è´¥å¤„ç†** â€” è®°å½•å¤±è´¥åŸå› ï¼Œä½¿ç”¨å·²æœ‰æ•°æ®ç»§ç»­åˆ†æï¼Œä¸é‡å¤è°ƒç”¨å¤±è´¥å·¥å…·ã€‚

{skills_section}
"""


# ============================================================
# Agent Executor
# ============================================================

class AgentExecutor:
    """ReAct agent loop with tool calling.

    Usage::

        executor = AgentExecutor(tool_registry, llm_adapter)
        result = executor.run("Analyze stock 600519")
    """

    def __init__(
        self,
        tool_registry: ToolRegistry,
        llm_adapter: LLMToolAdapter,
        skill_instructions: str = "",
        max_steps: int = 10,
    ):
        self.tool_registry = tool_registry
        self.llm_adapter = llm_adapter
        self.skill_instructions = skill_instructions
        self.max_steps = max_steps

    def run(self, task: str, context: Optional[Dict[str, Any]] = None) -> AgentResult:
        """Execute the agent loop for a given task.

        Args:
            task: The user task / analysis request.
            context: Optional context dict (e.g., {"stock_code": "600519"}).

        Returns:
            AgentResult with parsed dashboard or error.
        """
        start_time = time.time()
        tool_calls_log: List[Dict[str, Any]] = []
        total_tokens = 0

        # Build system prompt with skills
        skills_section = ""
        if self.skill_instructions:
            skills_section = f"## æ¿€æ´»çš„äº¤æ˜“ç­–ç•¥\n\n{self.skill_instructions}"
        system_prompt = AGENT_SYSTEM_PROMPT.format(skills_section=skills_section)

        # Build tool declarations for all providers
        tool_decls = {
            "gemini": self.tool_registry.to_gemini_declarations(),
            "openai": self.tool_registry.to_openai_tools(),
            "anthropic": self.tool_registry.to_anthropic_tools(),
        }

        # Initialize conversation
        messages: List[Dict[str, Any]] = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": self._build_user_message(task, context)},
        ]

        return self._run_loop(messages, tool_decls, start_time, tool_calls_log, total_tokens, parse_dashboard=True)

    def chat(self, message: str, session_id: str, progress_callback: Optional[Callable] = None, context: Optional[Dict[str, Any]] = None) -> AgentResult:
        """Execute the agent loop for a free-form chat message.

        Args:
            message: The user's chat message.
            session_id: The conversation session ID.
            progress_callback: Optional callback for streaming progress events.
            context: Optional context dict from previous analysis for data reuse.

        Returns:
            AgentResult with the text response.
        """
        from src.agent.conversation import conversation_manager
        
        start_time = time.time()
        tool_calls_log: List[Dict[str, Any]] = []
        total_tokens = 0

        # Build system prompt with skills
        skills_section = ""
        if self.skill_instructions:
            skills_section = f"## æ¿€æ´»çš„äº¤æ˜“ç­–ç•¥\n\n{self.skill_instructions}"
        system_prompt = CHAT_SYSTEM_PROMPT.format(skills_section=skills_section)

        # Build tool declarations for all providers
        tool_decls = {
            "gemini": self.tool_registry.to_gemini_declarations(),
            "openai": self.tool_registry.to_openai_tools(),
            "anthropic": self.tool_registry.to_anthropic_tools(),
        }

        # Get conversation history
        session = conversation_manager.get_or_create(session_id)
        history = session.get_history()

        # Initialize conversation
        messages: List[Dict[str, Any]] = [
            {"role": "system", "content": system_prompt},
        ]
        messages.extend(history)

        # Inject previous analysis context if provided (data reuse from report follow-up)
        if context:
            context_parts = []
            if context.get("stock_code"):
                context_parts.append(f"è‚¡ç¥¨ä»£ç : {context['stock_code']}")
            if context.get("stock_name"):
                context_parts.append(f"è‚¡ç¥¨åç§°: {context['stock_name']}")
            if context.get("previous_price"):
                context_parts.append(f"ä¸Šæ¬¡åˆ†æä»·æ ¼: {context['previous_price']}")
            if context.get("previous_change_pct"):
                context_parts.append(f"ä¸Šæ¬¡æ¶¨è·Œå¹…: {context['previous_change_pct']}%")
            if context.get("previous_analysis_summary"):
                summary = context["previous_analysis_summary"]
                summary_text = json.dumps(summary, ensure_ascii=False) if isinstance(summary, dict) else str(summary)
                context_parts.append(f"ä¸Šæ¬¡åˆ†ææ‘˜è¦:\n{summary_text}")
            if context.get("previous_strategy"):
                strategy = context["previous_strategy"]
                strategy_text = json.dumps(strategy, ensure_ascii=False) if isinstance(strategy, dict) else str(strategy)
                context_parts.append(f"ä¸Šæ¬¡ç­–ç•¥åˆ†æ:\n{strategy_text}")
            if context_parts:
                context_msg = "[ç³»ç»Ÿæä¾›çš„å†å²åˆ†æä¸Šä¸‹æ–‡ï¼Œå¯ä¾›å‚è€ƒå¯¹æ¯”]\n" + "\n".join(context_parts)
                messages.append({"role": "user", "content": context_msg})
                messages.append({"role": "assistant", "content": "å¥½çš„ï¼Œæˆ‘å·²äº†è§£è¯¥è‚¡ç¥¨çš„å†å²åˆ†ææ•°æ®ã€‚è¯·å‘Šè¯‰æˆ‘ä½ æƒ³äº†è§£ä»€ä¹ˆï¼Ÿ"})

        messages.append({"role": "user", "content": message})

        result = self._run_loop(messages, tool_decls, start_time, tool_calls_log, total_tokens, parse_dashboard=False, progress_callback=progress_callback)

        # Always persist the user turn; persist assistant reply (or error note) for context continuity
        conversation_manager.add_message(session_id, "user", message)
        if result.success:
            conversation_manager.add_message(session_id, "assistant", result.content)
        else:
            error_note = f"[åˆ†æå¤±è´¥] {result.error or 'æœªçŸ¥é”™è¯¯'}"
            conversation_manager.add_message(session_id, "assistant", error_note)

        return result

    def _run_loop(self, messages: List[Dict[str, Any]], tool_decls: Dict[str, Any], start_time: float, tool_calls_log: List[Dict[str, Any]], total_tokens: int, parse_dashboard: bool, progress_callback: Optional[Callable] = None) -> AgentResult:
        provider_used = ""

        for step in range(self.max_steps):
            logger.info(f"Agent step {step + 1}/{self.max_steps}")

            if progress_callback:
                if not tool_calls_log:
                    thinking_msg = "æ­£åœ¨åˆ¶å®šåˆ†æè·¯å¾„..."
                else:
                    last_tool = tool_calls_log[-1].get("tool", "")
                    label = _THINKING_TOOL_LABELS.get(last_tool, last_tool)
                    thinking_msg = f"ã€Œ{label}ã€å·²å®Œæˆï¼Œç»§ç»­æ·±å…¥åˆ†æ..."
                progress_callback({"type": "thinking", "step": step + 1, "message": thinking_msg})

            response = self.llm_adapter.call_with_tools(messages, tool_decls)
            provider_used = response.provider
            total_tokens += response.usage.get("total_tokens", 0)

            if response.tool_calls:
                # LLM wants to call tools
                logger.info(f"Agent requesting {len(response.tool_calls)} tool call(s): "
                          f"{[tc.name for tc in response.tool_calls]}")

                # Add assistant message with tool calls to history
                assistant_msg: Dict[str, Any] = {
                    "role": "assistant",
                    "content": response.content,
                    "tool_calls": [
                        {"id": tc.id, "name": tc.name, "arguments": tc.arguments}
                        for tc in response.tool_calls
                    ],
                }
                messages.append(assistant_msg)

                # Execute tool calls â€” parallel when multiple, sequential when single
                tool_results: List[Dict[str, Any]] = []

                def _exec_single_tool(tc_item):
                    """Execute one tool and return (tc, result_str, success, duration)."""
                    t0 = time.time()
                    try:
                        res = self.tool_registry.execute(tc_item.name, **tc_item.arguments)
                        res_str = self._serialize_tool_result(res)
                        ok = True
                    except Exception as e:
                        res_str = json.dumps({"error": str(e)})
                        ok = False
                        logger.warning(f"Tool '{tc_item.name}' failed: {e}")
                    dur = time.time() - t0
                    return tc_item, res_str, ok, round(dur, 2)

                if len(response.tool_calls) == 1:
                    # Single tool â€” run inline (no thread overhead)
                    tc = response.tool_calls[0]
                    if progress_callback:
                        progress_callback({"type": "tool_start", "step": step + 1, "tool": tc.name})
                    _, result_str, success, tool_duration = _exec_single_tool(tc)
                    if progress_callback:
                        progress_callback({"type": "tool_done", "step": step + 1, "tool": tc.name, "success": success, "duration": tool_duration})
                    tool_calls_log.append({
                        "step": step + 1, "tool": tc.name, "arguments": tc.arguments,
                        "success": success, "duration": tool_duration, "result_length": len(result_str),
                    })
                    tool_results.append({"tc": tc, "result_str": result_str})
                else:
                    # Multiple tools â€” run in parallel threads
                    for tc in response.tool_calls:
                        if progress_callback:
                            progress_callback({"type": "tool_start", "step": step + 1, "tool": tc.name})

                    with ThreadPoolExecutor(max_workers=min(len(response.tool_calls), 5)) as pool:
                        futures = {pool.submit(_exec_single_tool, tc): tc for tc in response.tool_calls}
                        for future in as_completed(futures):
                            tc_item, result_str, success, tool_duration = future.result()
                            if progress_callback:
                                progress_callback({"type": "tool_done", "step": step + 1, "tool": tc_item.name, "success": success, "duration": tool_duration})
                            tool_calls_log.append({
                                "step": step + 1, "tool": tc_item.name, "arguments": tc_item.arguments,
                                "success": success, "duration": tool_duration, "result_length": len(result_str),
                            })
                            tool_results.append({"tc": tc_item, "result_str": result_str})

                # Append tool results to messages (ordered by original tool_calls order)
                tc_order = {tc.id: i for i, tc in enumerate(response.tool_calls)}
                tool_results.sort(key=lambda x: tc_order.get(x["tc"].id, 0))
                for tr in tool_results:
                    messages.append({
                        "role": "tool",
                        "name": tr["tc"].name,
                        "tool_call_id": tr["tc"].id,
                        "content": tr["result_str"],
                    })

            else:
                # LLM returned text â€” this is the final answer
                logger.info(f"Agent completed in {step + 1} steps "
                          f"({time.time() - start_time:.1f}s, {total_tokens} tokens)")
                if progress_callback:
                    progress_callback({"type": "generating", "step": step + 1, "message": "æ­£åœ¨ç”Ÿæˆæœ€ç»ˆåˆ†æ..."})

                final_content = response.content or ""
                
                if parse_dashboard:
                    dashboard = self._parse_dashboard(final_content)
                    return AgentResult(
                        success=dashboard is not None,
                        content=final_content,
                        dashboard=dashboard,
                        tool_calls_log=tool_calls_log,
                        total_steps=step + 1,
                        total_tokens=total_tokens,
                        provider=provider_used,
                        error=None if dashboard else "Failed to parse dashboard JSON from agent response",
                    )
                else:
                    if response.provider == "error":
                        return AgentResult(
                            success=False,
                            content="",
                            dashboard=None,
                            tool_calls_log=tool_calls_log,
                            total_steps=step + 1,
                            total_tokens=total_tokens,
                            provider=provider_used,
                            error=final_content,
                        )
                    return AgentResult(
                        success=True,
                        content=final_content,
                        dashboard=None,
                        tool_calls_log=tool_calls_log,
                        total_steps=step + 1,
                        total_tokens=total_tokens,
                        provider=provider_used,
                        error=None,
                    )

        # Max steps exceeded
        logger.warning(f"Agent hit max steps ({self.max_steps})")
        return AgentResult(
            success=False,
            content="",
            tool_calls_log=tool_calls_log,
            total_steps=self.max_steps,
            total_tokens=total_tokens,
            provider=provider_used,
            error=f"Agent exceeded max steps ({self.max_steps})",
        )

    def _build_user_message(self, task: str, context: Optional[Dict[str, Any]] = None) -> str:
        """Build the initial user message."""
        parts = [task]
        if context:
            if context.get("stock_code"):
                parts.append(f"\nè‚¡ç¥¨ä»£ç : {context['stock_code']}")
            if context.get("report_type"):
                parts.append(f"æŠ¥å‘Šç±»å‹: {context['report_type']}")
            
            # æ³¨å…¥å·²æœ‰çš„ä¸Šä¸‹æ–‡æ•°æ®ï¼Œé¿å…é‡å¤è·å–
            if context.get("realtime_quote"):
                parts.append(f"\n[ç³»ç»Ÿå·²è·å–çš„å®æ—¶è¡Œæƒ…]\n{json.dumps(context['realtime_quote'], ensure_ascii=False)}")
            if context.get("chip_distribution"):
                parts.append(f"\n[ç³»ç»Ÿå·²è·å–çš„ç­¹ç åˆ†å¸ƒ]\n{json.dumps(context['chip_distribution'], ensure_ascii=False)}")
                
        parts.append("\nè¯·ä½¿ç”¨å¯ç”¨å·¥å…·è·å–ç¼ºå¤±çš„æ•°æ®ï¼ˆå¦‚å†å²Kçº¿ã€æ–°é—»ç­‰ï¼‰ï¼Œç„¶åä»¥å†³ç­–ä»ªè¡¨ç›˜ JSON æ ¼å¼è¾“å‡ºåˆ†æç»“æœã€‚")
        return "\n".join(parts)

    def _serialize_tool_result(self, result: Any) -> str:
        """Serialize a tool result to a JSON string for the LLM."""
        if result is None:
            return json.dumps({"result": None})
        if isinstance(result, str):
            return result
        if isinstance(result, (dict, list)):
            try:
                return json.dumps(result, ensure_ascii=False, default=str)
            except (TypeError, ValueError):
                return str(result)
        # Dataclass or object with __dict__
        if hasattr(result, '__dict__'):
            try:
                d = {k: v for k, v in result.__dict__.items() if not k.startswith('_')}
                return json.dumps(d, ensure_ascii=False, default=str)
            except (TypeError, ValueError):
                return str(result)
        return str(result)

    def _parse_dashboard(self, content: str) -> Optional[Dict[str, Any]]:
        """Extract and parse the Decision Dashboard JSON from agent response."""
        if not content:
            return None

        # Try to extract JSON from markdown code blocks
        json_blocks = re.findall(r'```(?:json)?\s*\n?(.*?)\n?```', content, re.DOTALL)
        if json_blocks:
            for block in json_blocks:
                try:
                    parsed = json.loads(block)
                    if isinstance(parsed, dict):
                        return parsed
                except json.JSONDecodeError:
                    try:
                        repaired = repair_json(block)
                        parsed = json.loads(repaired)
                        if isinstance(parsed, dict):
                            return parsed
                    except Exception:
                        continue

        # Try raw JSON parse
        try:
            parsed = json.loads(content)
            if isinstance(parsed, dict):
                return parsed
        except json.JSONDecodeError:
            pass

        # Try json_repair
        try:
            repaired = repair_json(content)
            parsed = json.loads(repaired)
            if isinstance(parsed, dict):
                return parsed
        except Exception:
            pass

        # Try to find JSON object in text
        brace_start = content.find('{')
        brace_end = content.rfind('}')
        if brace_start >= 0 and brace_end > brace_start:
            candidate = content[brace_start:brace_end + 1]
            try:
                parsed = json.loads(candidate)
                if isinstance(parsed, dict):
                    return parsed
            except json.JSONDecodeError:
                try:
                    repaired = repair_json(candidate)
                    parsed = json.loads(repaired)
                    if isinstance(parsed, dict):
                        return parsed
                except Exception:
                    pass

        logger.warning("Failed to parse dashboard JSON from agent response")
        return None
