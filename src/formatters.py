# -*- coding: utf-8 -*-
"""
===================================
æ ¼å¼åŒ–å·¥å…·æ¨¡å—
===================================

æä¾›å„ç§å†…å®¹æ ¼å¼åŒ–å·¥å…·å‡½æ•°ï¼Œç”¨äºå°†é€šç”¨æ ¼å¼è½¬æ¢ä¸ºå¹³å°ç‰¹å®šæ ¼å¼ã€‚
"""

import re
import time
from typing import List, Callable

import markdown2


TRUNCATION_SUFFIX = "\n\n...(æœ¬æ®µå†…å®¹è¿‡é•¿å·²æˆªæ–­)"
MIN_MAX_WORDS = 10

# Unicode code point ranges for emoji (symbols that count as 2 for effective length).
_EMOJI_RANGES = [
    (0x2600, 0x26FF),   # Misc symbols
    (0x2700, 0x27BF),   # Dingbats
    (0x1F300, 0x1F5FF), # Misc Symbols and Pictographs
    (0x1F600, 0x1F64F), # Emoticons
    (0x1F650, 0x1F67F),
    (0x1F680, 0x1F6FF), # Transport and Map
    (0x1F900, 0x1F9FF), # Supplemental Symbols and Pictographs
    (0x1F1E0, 0x1F1FF), # Flags
]


def _is_emoji(c: str) -> bool:
    """åˆ¤æ–­å­—ç¬¦æ˜¯å¦ä¸º emoji
    
    Args:
        c: å­—ç¬¦
        
    Returns:
        True å¦‚æœå­—ç¬¦ä¸º emojiï¼ŒFalse å¦åˆ™
    """
    if len(c) != 1:
        return False
    cp = ord(c)
    return any(lo <= cp <= hi for lo, hi in _EMOJI_RANGES)


def _effective_len(s: str, emoji_len: int = 2) -> int:
    """
    è®¡ç®—å­—ç¬¦ä¸²çš„æœ‰æ•ˆé•¿åº¦
    
    Args:
        s: å­—ç¬¦ä¸²
        emoji_len: æ¯ä¸ª emoji çš„é•¿åº¦ï¼Œé»˜è®¤ä¸º 2
        
    Returns:
        s çš„æœ‰æ•ˆé•¿åº¦
    """
    n = len(s)
    n += sum(emoji_len - 1 for c in s if _is_emoji(c))
    return n


def _slice_at_effective_len(s: str, effective_len: int, emoji_len: int = 2) -> tuple[str, str]:
    """
    æŒ‰æœ‰æ•ˆé•¿åº¦åˆ†å‰²å­—ç¬¦ä¸²
    
    Args:
        s: å­—ç¬¦ä¸²
        effective_len: æœ‰æ•ˆé•¿åº¦
        emoji_len: æ¯ä¸ª emoji çš„é•¿åº¦ï¼Œé»˜è®¤ä¸º 2
        
    Returns:
        åˆ†å‰²åçš„å‰ã€åéƒ¨åˆ†å­—ç¬¦ä¸²
    """
    if _effective_len(s, emoji_len) <= effective_len:
        return s, ""
    eff = 0
    for i, c in enumerate(s):
        eff += emoji_len if _is_emoji(c) else 1
        if eff > effective_len:
            return s[:i], s[i:]
    return s, ""


def markdown_to_html_document(markdown_text: str) -> str:
    """
    Convert Markdown to a complete HTML document (for email, md2img, etc.).

    Uses markdown2 with table and code block support, wraps with inline CSS
    for compact, readable layout. Reused by notification email and md2img.

    Args:
        markdown_text: Raw Markdown content.

    Returns:
        Full HTML document string with DOCTYPE, head, and body.
    """
    html_content = markdown2.markdown(
        markdown_text,
        extras=["tables", "fenced-code-blocks", "break-on-newline", "cuddled-lists"],
    )

    css_style = """
            body {
                font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
                line-height: 1.5;
                color: #24292e;
                font-size: 14px;
                padding: 15px;
                max-width: 900px;
                margin: 0 auto;
            }
            h1 {
                font-size: 20px;
                border-bottom: 1px solid #eaecef;
                padding-bottom: 0.3em;
                margin-top: 1.2em;
                margin-bottom: 0.8em;
                color: #0366d6;
            }
            h2 {
                font-size: 18px;
                border-bottom: 1px solid #eaecef;
                padding-bottom: 0.3em;
                margin-top: 1.0em;
                margin-bottom: 0.6em;
            }
            h3 {
                font-size: 16px;
                margin-top: 0.8em;
                margin-bottom: 0.4em;
            }
            p {
                margin-top: 0;
                margin-bottom: 8px;
            }
            table {
                border-collapse: collapse;
                width: 100%;
                margin: 12px 0;
                display: block;
                overflow-x: auto;
                font-size: 13px;
            }
            th, td {
                border: 1px solid #dfe2e5;
                padding: 6px 10px;
                text-align: left;
            }
            th {
                background-color: #f6f8fa;
                font-weight: 600;
            }
            tr:nth-child(2n) {
                background-color: #f8f8f8;
            }
            tr:hover {
                background-color: #f1f8ff;
            }
            blockquote {
                color: #6a737d;
                border-left: 0.25em solid #dfe2e5;
                padding: 0 1em;
                margin: 0 0 10px 0;
            }
            code {
                padding: 0.2em 0.4em;
                margin: 0;
                font-size: 85%;
                background-color: rgba(27,31,35,0.05);
                border-radius: 3px;
                font-family: SFMono-Regular, Consolas, "Liberation Mono", Menlo, monospace;
            }
            pre {
                padding: 12px;
                overflow: auto;
                line-height: 1.45;
                background-color: #f6f8fa;
                border-radius: 3px;
                margin-bottom: 10px;
            }
            hr {
                height: 0.25em;
                padding: 0;
                margin: 16px 0;
                background-color: #e1e4e8;
                border: 0;
            }
            ul, ol {
                padding-left: 20px;
                margin-bottom: 10px;
            }
            li {
                margin: 2px 0;
            }
        """

    return f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="utf-8">
            <style>
                {css_style}
            </style>
        </head>
        <body>
            {html_content}
        </body>
        </html>
        """


def markdown_to_plain_text(markdown_text: str) -> str:
    """
    å°† Markdown è½¬æ¢ä¸ºçº¯æ–‡æœ¬
    
    ç§»é™¤ Markdown æ ¼å¼æ ‡è®°ï¼Œä¿ç•™å¯è¯»æ€§
    """
    text = markdown_text
    
    # ç§»é™¤æ ‡é¢˜æ ‡è®° # ## ###
    text = re.sub(r'^#{1,6}\s+', '', text, flags=re.MULTILINE)
    
    # ç§»é™¤åŠ ç²— **text** -> text
    text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)
    
    # ç§»é™¤æ–œä½“ *text* -> text
    text = re.sub(r'\*(.+?)\*', r'\1', text)
    
    # ç§»é™¤å¼•ç”¨ > text -> text
    text = re.sub(r'^>\s+', '', text, flags=re.MULTILINE)
    
    # ç§»é™¤åˆ—è¡¨æ ‡è®° - item -> item
    text = re.sub(r'^[-*]\s+', 'â€¢ ', text, flags=re.MULTILINE)
    
    # ç§»é™¤åˆ†éš”çº¿ ---
    text = re.sub(r'^---+$', 'â”€â”€â”€â”€â”€â”€â”€â”€', text, flags=re.MULTILINE)
    
    # ç§»é™¤è¡¨æ ¼è¯­æ³• |---|---|
    text = re.sub(r'\|[-:]+\|[-:|\s]+\|', '', text)
    text = re.sub(r'^\|(.+)\|$', r'\1', text, flags=re.MULTILINE)
    
    # æ¸…ç†å¤šä½™ç©ºè¡Œ
    text = re.sub(r'\n{3,}', '\n\n', text)
    
    return text.strip()


def chunk_markdown_by_bytes(content: str, max_bytes: int) -> List[str]:
    def get_bytes(s: str) -> int:
        return len(s.encode('utf-8'))

    def split_by_bytes(text: str, limit: int) -> List[str]:
        parts: List[str] = []
        remaining = text
        while remaining:
            part = truncate_to_bytes(remaining, limit)
            if not part:
                break
            parts.append(part)
            remaining = remaining[len(part):]
        return parts

    # ä¼˜å…ˆæŒ‰åˆ†éš”çº¿/æ ‡é¢˜åˆ†å‰²ï¼Œä¿è¯åˆ†é¡µè‡ªç„¶
    if "\n---\n" in content:
        sections = content.split("\n---\n")
        separator = "\n---\n"
    elif "\n### " in content:
        parts = content.split("\n### ")
        sections = [parts[0]] + [f"### {p}" for p in parts[1:]]
        separator = "\n"
    else:
        # fallbackï¼šæŒ‰è¡Œæ‹¼æ¥
        sections = content.split("\n")
        separator = "\n"

    chunks: List[str] = []
    current_chunk: List[str] = []
    current_bytes = 0
    sep_bytes = get_bytes(separator)

    for section in sections:
        section_bytes = get_bytes(section)
        extra = sep_bytes if current_chunk else 0

        # å•æ®µè¶…é•¿ï¼šæˆªæ–­
        if section_bytes + extra > max_bytes:
            if current_chunk:
                chunks.append(separator.join(current_chunk))
                current_chunk = []
                current_bytes = 0

            # æ— æ³•æŒ‰ç»“æ„æ‹†åˆ†æ—¶ï¼ŒæŒ‰å­—èŠ‚å¼ºåˆ¶æ‹†åˆ†ï¼Œé¿å…æ•´æ®µè¢«æˆªæ–­ä¸¢å¤±
            for part in split_by_bytes(section, max(200, max_bytes - 200)):
                chunks.append(part)
            continue

        if current_bytes + section_bytes + extra > max_bytes:
            chunks.append(separator.join(current_chunk))
            current_chunk = [section]
            current_bytes = section_bytes
        else:
            if current_chunk:
                current_bytes += sep_bytes
            current_chunk.append(section)
            current_bytes += section_bytes

    if current_chunk:
        chunks.append(separator.join(current_chunk))

    # ç§»é™¤ç©ºå—
    return [c for c in (c.strip() for c in chunks) if c]


def format_feishu_markdown(content: str) -> str:
    """
    å°†é€šç”¨ Markdown è½¬æ¢ä¸ºé£ä¹¦ lark_md æ›´å‹å¥½çš„æ ¼å¼
    
    è½¬æ¢è§„åˆ™ï¼š
    - é£ä¹¦ä¸æ”¯æŒ Markdown æ ‡é¢˜ï¼ˆ# / ## / ###ï¼‰ï¼Œç”¨åŠ ç²—ä»£æ›¿
    - å¼•ç”¨å—ä½¿ç”¨å‰ç¼€æ›¿ä»£
    - åˆ†éš”çº¿ç»Ÿä¸€ä¸ºç»†çº¿
    - è¡¨æ ¼è½¬æ¢ä¸ºæ¡ç›®åˆ—è¡¨
    
    Args:
        content: åŸå§‹ Markdown å†…å®¹
        
    Returns:
        è½¬æ¢åçš„é£ä¹¦ Markdown æ ¼å¼å†…å®¹
        
    Example:
        >>> markdown = "# æ ‡é¢˜\\n> å¼•ç”¨\\n| åˆ—1 | åˆ—2 |"
        >>> formatted = format_feishu_markdown(markdown)
        >>> print(formatted)
        **æ ‡é¢˜**
        ğŸ’¬ å¼•ç”¨
        â€¢ åˆ—1ï¼šå€¼1 | åˆ—2ï¼šå€¼2
    """
    def _flush_table_rows(buffer: List[str], output: List[str]) -> None:
        """å°†è¡¨æ ¼ç¼“å†²åŒºä¸­çš„è¡Œè½¬æ¢ä¸ºé£ä¹¦æ ¼å¼"""
        if not buffer:
            return

        def _parse_row(row: str) -> List[str]:
            """è§£æè¡¨æ ¼è¡Œï¼Œæå–å•å…ƒæ ¼"""
            cells = [c.strip() for c in row.strip().strip('|').split('|')]
            return [c for c in cells if c]

        rows = []
        for raw in buffer:
            # è·³è¿‡åˆ†éš”è¡Œï¼ˆå¦‚ |---|---|ï¼‰
            if re.match(r'^\s*\|?\s*[:-]+\s*(\|\s*[:-]+\s*)+\|?\s*$', raw):
                continue
            parsed = _parse_row(raw)
            if parsed:
                rows.append(parsed)

        if not rows:
            return

        header = rows[0]
        data_rows = rows[1:] if len(rows) > 1 else []
        for row in data_rows:
            pairs = []
            for idx, cell in enumerate(row):
                key = header[idx] if idx < len(header) else f"åˆ—{idx + 1}"
                pairs.append(f"{key}ï¼š{cell}")
            output.append(f"â€¢ {' | '.join(pairs)}")

    lines = []
    table_buffer: List[str] = []

    for raw_line in content.splitlines():
        line = raw_line.rstrip()

        # å¤„ç†è¡¨æ ¼è¡Œ
        if line.strip().startswith('|'):
            table_buffer.append(line)
            continue

        # åˆ·æ–°è¡¨æ ¼ç¼“å†²åŒº
        if table_buffer:
            _flush_table_rows(table_buffer, lines)
            table_buffer = []

        # è½¬æ¢æ ‡é¢˜ï¼ˆ# ## ### ç­‰ï¼‰
        if re.match(r'^#{1,6}\s+', line):
            title = re.sub(r'^#{1,6}\s+', '', line).strip()
            line = f"**{title}**" if title else ""
        # è½¬æ¢å¼•ç”¨å—
        elif line.startswith('> '):
            quote = line[2:].strip()
            line = f"ğŸ’¬ {quote}" if quote else ""
        # è½¬æ¢åˆ†éš”çº¿
        elif line.strip() == '---':
            line = 'â”€â”€â”€â”€â”€â”€â”€â”€'
        # è½¬æ¢åˆ—è¡¨é¡¹
        elif line.startswith('- '):
            line = f"â€¢ {line[2:].strip()}"

        lines.append(line)

    # å¤„ç†æœ«å°¾çš„è¡¨æ ¼
    if table_buffer:
        _flush_table_rows(table_buffer, lines)

    return "\n".join(lines).strip()


def truncate_to_bytes(text: str, max_bytes: int) -> str:
    """
    æŒ‰å­—èŠ‚æ•°æˆªæ–­å­—ç¬¦ä¸²ï¼Œç¡®ä¿ä¸ä¼šåœ¨å¤šå­—èŠ‚å­—ç¬¦ä¸­é—´æˆªæ–­

    Args:
        text: è¦æˆªæ–­çš„å­—ç¬¦ä¸²
        max_bytes: æœ€å¤§å­—èŠ‚æ•°

    Returns:
        æˆªæ–­åçš„å­—ç¬¦ä¸²
    """
    encoded = text.encode("utf-8")
    if len(encoded) <= max_bytes:
        return text

    # ä» max_bytes ä½ç½®å¾€å‰æ‰¾ï¼Œç¡®ä¿ä¸æˆªæ–­å¤šå­—èŠ‚å­—ç¬¦
    truncated = encoded[:max_bytes]
    # å°è¯•è§£ç ï¼Œå¦‚æœå¤±è´¥åˆ™ç»§ç»­å¾€å‰
    while truncated:
        try:
            return truncated.decode("utf-8")
        except UnicodeDecodeError:
            truncated = truncated[:-1]
    return ""


def _chunk_by_lines(content: str, max_bytes: int, send_func: Callable[[str], bool]) -> bool:
    """
    å¼ºåˆ¶æŒ‰è¡Œåˆ†å‰²å‘é€ï¼ˆæ— æ³•æ™ºèƒ½åˆ†å‰²æ—¶çš„ fallbackï¼‰
    
    Args:
        content: å®Œæ•´æ¶ˆæ¯å†…å®¹
        max_bytes: å•æ¡æ¶ˆæ¯æœ€å¤§å­—èŠ‚æ•°
        send_func: å‘é€å•æ¡æ¶ˆæ¯çš„å‡½æ•°
        
    Returns:
        æ˜¯å¦å…¨éƒ¨å‘é€æˆåŠŸ
    """
    chunks = []
    current_chunk = ""
    
    # æŒ‰è¡Œåˆ†å‰²ï¼Œç¡®ä¿ä¸ä¼šåœ¨å¤šå­—èŠ‚å­—ç¬¦ä¸­é—´æˆªæ–­
    lines = content.split('\n')
    
    for line in lines:
        test_chunk = current_chunk + ('\n' if current_chunk else '') + line
        if len(test_chunk.encode('utf-8')) > max_bytes - 100:  # é¢„ç•™ç©ºé—´ç»™åˆ†é¡µæ ‡è®°
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = line
        else:
            current_chunk = test_chunk
    
    if current_chunk:
        chunks.append(current_chunk)
    
    total_chunks = len(chunks)
    success_count = 0
    
    for i, chunk in enumerate(chunks):
        # æ·»åŠ åˆ†é¡µæ ‡è®°
        page_marker = f"\n\nğŸ“„ ({i+1}/{total_chunks})" if total_chunks > 1 else ""
        
        try:
            if send_func(chunk + page_marker):
                success_count += 1
        except Exception as e:
            import logging
            logger = logging.getLogger(__name__)
            logger.error(f"é£ä¹¦ç¬¬ {i+1}/{total_chunks} æ‰¹å‘é€å¼‚å¸¸: {e}")
        
        # æ‰¹æ¬¡é—´éš”ï¼Œé¿å…è§¦å‘é¢‘ç‡é™åˆ¶
        if i < total_chunks - 1:
            time.sleep(1)
    
    return success_count == total_chunks


def chunk_feishu_content(content: str, max_bytes: int, send_func: Callable[[str], bool]) -> bool:
    """
    å°†è¶…é•¿å†…å®¹åˆ†æ®µå‘é€åˆ°é£ä¹¦
    
    æ™ºèƒ½åˆ†å‰²ç­–ç•¥ï¼š
    1. ä¼˜å…ˆæŒ‰ "---" åˆ†éš”ï¼ˆè‚¡ç¥¨ä¹‹é—´çš„åˆ†éš”çº¿ï¼‰
    2. å…¶æ¬¡æŒ‰ "### " æ ‡é¢˜åˆ†å‰²ï¼ˆæ¯åªè‚¡ç¥¨çš„æ ‡é¢˜ï¼‰
    3. æœ€åæŒ‰è¡Œå¼ºåˆ¶åˆ†å‰²
    
    Args:
        content: å®Œæ•´æ¶ˆæ¯å†…å®¹
        max_bytes: å•æ¡æ¶ˆæ¯æœ€å¤§å­—èŠ‚æ•°
        send_func: å‘é€å•æ¡æ¶ˆæ¯çš„å‡½æ•°ï¼Œæ¥æ”¶å†…å®¹å­—ç¬¦ä¸²ï¼Œè¿”å›æ˜¯å¦æˆåŠŸ
        
    Returns:
        æ˜¯å¦å…¨éƒ¨å‘é€æˆåŠŸ
    """
    def get_bytes(s: str) -> int:
        """è·å–å­—ç¬¦ä¸²çš„ UTF-8 å­—èŠ‚æ•°"""
        return len(s.encode('utf-8'))
    
    def _truncate_to_bytes(text: str, max_bytes: int) -> str:
        """æŒ‰å­—èŠ‚æˆªæ–­æ–‡æœ¬ï¼Œç¡®ä¿ä¸ä¼šåœ¨å¤šå­—èŠ‚å­—ç¬¦ä¸­é—´æˆªæ–­"""
        encoded = text.encode('utf-8')
        if len(encoded) <= max_bytes:
            return text
        
        # ä»æœ€å¤§å­—èŠ‚æ•°å¼€å§‹å‘å‰æŸ¥æ‰¾ï¼Œæ‰¾åˆ°å®Œæ•´çš„ UTF-8 å­—ç¬¦è¾¹ç•Œ
        truncated = encoded[:max_bytes]
        while truncated and (truncated[-1] & 0xC0) == 0x80:
            truncated = truncated[:-1]
        
        return truncated.decode('utf-8', errors='ignore')
    
    # æ™ºèƒ½åˆ†å‰²ï¼šä¼˜å…ˆæŒ‰ "---" åˆ†éš”ï¼ˆè‚¡ç¥¨ä¹‹é—´çš„åˆ†éš”çº¿ï¼‰
    # å¦‚æœæ²¡æœ‰åˆ†éš”çº¿ï¼ŒæŒ‰ "### " æ ‡é¢˜åˆ†å‰²ï¼ˆæ¯åªè‚¡ç¥¨çš„æ ‡é¢˜ï¼‰
    if "\n---\n" in content:
        sections = content.split("\n---\n")
        separator = "\n---\n"
    elif "\n### " in content:
        # æŒ‰ ### åˆ†å‰²ï¼Œä½†ä¿ç•™ ### å‰ç¼€
        parts = content.split("\n### ")
        sections = [parts[0]] + [f"### {p}" for p in parts[1:]]
        separator = "\n"
    else:
        # æ— æ³•æ™ºèƒ½åˆ†å‰²ï¼ŒæŒ‰è¡Œå¼ºåˆ¶åˆ†å‰²
        return _chunk_by_lines(content, max_bytes, send_func)
    
    chunks = []
    current_chunk = []
    current_bytes = 0
    separator_bytes = get_bytes(separator)
    
    for section in sections:
        section_bytes = get_bytes(section) + separator_bytes
        
        # å¦‚æœå•ä¸ª section å°±è¶…é•¿ï¼Œéœ€è¦å¼ºåˆ¶æˆªæ–­
        if section_bytes > max_bytes:
            # å…ˆå‘é€å½“å‰ç§¯ç´¯çš„å†…å®¹
            if current_chunk:
                chunks.append(separator.join(current_chunk))
                current_chunk = []
                current_bytes = 0
            
            # å¼ºåˆ¶æˆªæ–­è¿™ä¸ªè¶…é•¿ sectionï¼ˆæŒ‰å­—èŠ‚æˆªæ–­ï¼‰
            truncated = _truncate_to_bytes(section, max_bytes - 200)
            truncated += "\n\n...(æœ¬æ®µå†…å®¹è¿‡é•¿å·²æˆªæ–­)"
            chunks.append(truncated)
            continue
        
        # æ£€æŸ¥åŠ å…¥åæ˜¯å¦è¶…é•¿
        if current_bytes + section_bytes > max_bytes:
            # ä¿å­˜å½“å‰å—ï¼Œå¼€å§‹æ–°å—
            if current_chunk:
                chunks.append(separator.join(current_chunk))
            current_chunk = [section]
            current_bytes = section_bytes
        else:
            current_chunk.append(section)
            current_bytes += section_bytes
    
    # æ·»åŠ æœ€åä¸€å—
    if current_chunk:
        chunks.append(separator.join(current_chunk))
    
    # åˆ†æ‰¹å‘é€
    total_chunks = len(chunks)
    success_count = 0
    
    for i, chunk in enumerate(chunks):
        # æ·»åŠ åˆ†é¡µæ ‡è®°
        if total_chunks > 1:
            page_marker = f"\n\nğŸ“„ ({i+1}/{total_chunks})"
            chunk_with_marker = chunk + page_marker
        else:
            chunk_with_marker = chunk
        
        try:
            if send_func(chunk_with_marker):
                success_count += 1
        except Exception as e:
            import logging
            logger = logging.getLogger(__name__)
            logger.error(f"é£ä¹¦ç¬¬ {i+1}/{total_chunks} æ‰¹å‘é€å¼‚å¸¸: {e}")
        
        # æ‰¹æ¬¡é—´éš”ï¼Œé¿å…è§¦å‘é¢‘ç‡é™åˆ¶
        if i < total_chunks - 1:
            time.sleep(1)
    
    return success_count == total_chunks


def _chunk_by_separators(content: str) -> tuple[list[str], str]:
    """
    é€šè¿‡åˆ†å‰²çº¿ç­‰ç‰¹æ®Šå­—ç¬¦å°†æ¶ˆæ¯å†…å®¹åˆ†å‰²ä¸ºå¤šä¸ªåŒºå—
    
    Args:
        content: å®Œæ•´æ¶ˆæ¯å†…å®¹
        
    Returns:
        sections: åˆ†å‰²åçš„åŒºå—åˆ—è¡¨
        separator: åŒºå—ä¹‹é—´çš„åˆ†éš”ç¬¦ï¼ŒNone è¡¨ç¤ºæ— æ³•åˆ†å‰²
    """
    # æ™ºèƒ½åˆ†å‰²ï¼šä¼˜å…ˆæŒ‰ "---" åˆ†éš”ï¼ˆè‚¡ç¥¨ä¹‹é—´çš„åˆ†éš”çº¿ï¼‰
    # å…¶æ¬¡å°è¯•å„çº§æ ‡é¢˜åˆ†å‰²
    if "\n---\n" in content:
        sections = content.split("\n---\n")
        separator = "\n---\n"
    elif "\n# " in content:
        # æŒ‰ # åˆ†å‰² (å…¼å®¹ä¸€çº§æ ‡é¢˜)
        parts = content.split("\n## ")
        sections = [parts[0]] + [f"## {p}" for p in parts[1:]]
        separator = "\n"
    elif "\n## " in content:
        # æŒ‰ ## åˆ†å‰² (å…¼å®¹äºŒçº§æ ‡é¢˜)
        parts = content.split("\n## ")
        sections = [parts[0]] + [f"## {p}" for p in parts[1:]]
        separator = "\n"
    elif "\n### " in content:
        # æŒ‰ ### åˆ†å‰²
        parts = content.split("\n### ")
        sections = [parts[0]] + [f"### {p}" for p in parts[1:]]
        separator = "\n"
    elif "\n**" in content:
        # æŒ‰ ** åŠ ç²—æ ‡é¢˜åˆ†å‰² (å…¼å®¹ AI æœªè¾“å‡ºæ ‡å‡† Markdown æ ‡é¢˜çš„æƒ…å†µ)
        parts = content.split("\n**")
        sections = [parts[0]] + [f"**{p}" for p in parts[1:]]
        separator = "\n"
    else:
        return [content], ""
    return sections, separator

def _chunk_by_max_words(content: str, max_words: int, emoji_len: int = 2) -> list[str]:
    """
    æŒ‰å­—æ•°åˆ†å‰²æ¶ˆæ¯å†…å®¹
    
    Args:
        content: å®Œæ•´æ¶ˆæ¯å†…å®¹
        max_words: å•æ¡æ¶ˆæ¯æœ€å¤§å­—æ•°
        emoji_len: æ¯ä¸ª emoji çš„é•¿åº¦ï¼Œé»˜è®¤ä¸º 2
        
    Returns:
        åˆ†å‰²åçš„åŒºå—åˆ—è¡¨
    """
    if _effective_len(content, emoji_len) <= max_words:
        return [content]
    if max_words < MIN_MAX_WORDS:
        raise ValueError(
            f"max_words={max_words} < {MIN_MAX_WORDS}, å¯èƒ½é™·å…¥æ— é™é€’å½’ã€‚"
        )

    sections = []
    suffix = TRUNCATION_SUFFIX
    effective_max_words = max_words - len(suffix)  # é¢„ç•™åç¼€ï¼Œé¿å…è¾¹ç•Œè¶…é™
    if effective_max_words <= 0:
        effective_max_words = max_words
        suffix = ""

    while True:
        chunk, content = _slice_at_effective_len(content, effective_max_words, emoji_len)
        sections.append(chunk + suffix)
        effective_len = _effective_len(content, emoji_len)
        if effective_len <= effective_max_words:
            if effective_len > 0:
                sections.append(content)
            break
    return sections

def chunk_content_by_max_words(content: str, max_words: int, emoji_len: int = 2) -> list[str]:
    """
    æŒ‰å­—æ•°æ™ºèƒ½åˆ†å‰²æ¶ˆæ¯å†…å®¹
    
    Args:
        content: å®Œæ•´æ¶ˆæ¯å†…å®¹
        max_words: å•æ¡æ¶ˆæ¯æœ€å¤§å­—æ•°
        emoji_len: æ¯ä¸ª emoji çš„é•¿åº¦ï¼Œé»˜è®¤ä¸º 2
        
    Returns:
        åˆ†å‰²åçš„åŒºå—åˆ—è¡¨
    """
    if max_words < MIN_MAX_WORDS:
        # Safe guardï¼Œé¿å…æ— é™é€’å½’
        # ç†è®ºä¸Šï¼Œmax_wordsåœ¨æ¯æ¬¡é€’å½’ä¸­å¯ä»¥å‡å°åˆ°æ— é™å°ï¼Œä½†å®é™…ä¸­ä¸å¤ªå¯èƒ½å‘ç”Ÿï¼Œ
        # é™¤éæ¯æ¬¡_chunk_by_separatorséƒ½èƒ½æˆåŠŸè¿”å›åˆ†éš”ç¬¦ï¼Œä¸”max_wordsåˆå§‹å€¼å¤ªå°ã€‚
        raise ValueError(f"max_words={max_words} < {MIN_MAX_WORDS}, å¯èƒ½é™·å…¥æ— é™é€’å½’ã€‚")
    
    if _effective_len(content, emoji_len) <= max_words:
        return [content]

    sections, separator = _chunk_by_separators(content)
    if separator == "":
        # æ— æ³•æ™ºèƒ½åˆ†å‰²ï¼Œåˆ™å¼ºåˆ¶æŒ‰å­—æ•°åˆ†å‰²
        return _chunk_by_max_words(content, max_words, emoji_len)

    chunks = []
    current_chunk = []
    current_word_len = 0
    separator_len = len(separator) if separator else 0
    effective_max_words = max_words - separator_len # é¢„ç•™åˆ†å‰²ç¬¦é•¿åº¦ï¼Œé¿å…è¾¹ç•Œè¶…é™

    for section in sections:
        section = section + separator
        section_word_len = _effective_len(section, emoji_len)

        # å¦‚æœå•ä¸ª section å°±è¶…é•¿ï¼Œéœ€è¦å¼ºåˆ¶æˆªæ–­
        if section_word_len > max_words:
            # å…ˆä¿å­˜å½“å‰ç§¯ç´¯çš„å†…å®¹
            if current_chunk:
                chunks.append("".join(current_chunk))
                current_chunk = []
                current_word_len = 0

            # å¼ºåˆ¶æˆªæ–­è¿™ä¸ªè¶…é•¿ section
            section_chunks = chunk_content_by_max_words(
                section[:-separator_len], effective_max_words, emoji_len
                )
            section_chunks[-1] = section_chunks[-1] + separator
            chunks.extend(section_chunks)
            continue

        # æ£€æŸ¥åŠ å…¥åæ˜¯å¦è¶…é•¿
        if current_word_len + section_word_len > max_words:
            # ä¿å­˜å½“å‰å—ï¼Œå¼€å§‹æ–°å—
            if current_chunk:
                chunks.append("".join(current_chunk))
            current_chunk = [section]
            current_word_len = section_word_len
        else:
            current_chunk.append(section)
            current_word_len += section_word_len

    # æ·»åŠ æœ€åä¸€å—
    if current_chunk:
        chunks.append("".join(current_chunk))

    # ç§»é™¤æœ€åä¸€ä¸ªå—çš„åˆ†å‰²ç¬¦
    if (chunks and
        len(chunks[-1]) > separator_len and
        chunks[-1][-separator_len:] == separator
        ):
        chunks[-1] = chunks[-1][:-separator_len]
    return chunks
